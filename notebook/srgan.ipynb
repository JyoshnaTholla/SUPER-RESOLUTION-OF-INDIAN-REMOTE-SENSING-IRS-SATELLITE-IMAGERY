{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f744338",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-16T20:08:05.404477Z",
     "iopub.status.busy": "2025-02-16T20:08:05.404165Z",
     "iopub.status.idle": "2025-02-16T20:08:19.092097Z",
     "shell.execute_reply": "2025-02-16T20:08:19.091420Z"
    },
    "papermill": {
     "duration": 13.695438,
     "end_time": "2025-02-16T20:08:19.093729",
     "exception": false,
     "start_time": "2025-02-16T20:08:05.398291",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import (Conv2D, Lambda, LeakyReLU, Dense, Input, add, concatenate, Flatten, BatchNormalization, PReLU, UpSampling2D)\n",
    "from keras.applications.vgg19 import VGG19, preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16631928",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-16T20:08:19.103524Z",
     "iopub.status.busy": "2025-02-16T20:08:19.103029Z",
     "iopub.status.idle": "2025-02-16T20:08:19.106904Z",
     "shell.execute_reply": "2025-02-16T20:08:19.106128Z"
    },
    "papermill": {
     "duration": 0.00987,
     "end_time": "2025-02-16T20:08:19.108227",
     "exception": false,
     "start_time": "2025-02-16T20:08:19.098357",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Helper Function to Convert BGR -> RGB for Display ---\n",
    "def bgr_to_rgb(image):\n",
    "    \"\"\"Convert a BGR image (H,W,3) to RGB for display purposes.\"\"\"\n",
    "    return image[..., ::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7f7aee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-16T20:08:19.117140Z",
     "iopub.status.busy": "2025-02-16T20:08:19.116934Z",
     "iopub.status.idle": "2025-02-16T20:08:20.147060Z",
     "shell.execute_reply": "2025-02-16T20:08:20.146397Z"
    },
    "papermill": {
     "duration": 1.036099,
     "end_time": "2025-02-16T20:08:20.148602",
     "exception": false,
     "start_time": "2025-02-16T20:08:19.112503",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Learning Rate Schedule ---\n",
    "def lr_schedule(epoch):\n",
    "    if epoch < 10:\n",
    "        return 1e-5  # Warmup phase\n",
    "    else:\n",
    "        return 1e-4 * (0.95 ** (epoch // 10))\n",
    "\n",
    "# Initialize optimizers \n",
    "gen_optimizer = tf.keras.optimizers.Adam(lr_schedule(0))\n",
    "disc_optimizer = tf.keras.optimizers.Adam(1e-5)  # Generator LR=1e-4, Discriminator LR=1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023885a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-16T20:08:20.158038Z",
     "iopub.status.busy": "2025-02-16T20:08:20.157793Z",
     "iopub.status.idle": "2025-02-16T20:08:20.168906Z",
     "shell.execute_reply": "2025-02-16T20:08:20.168161Z"
    },
    "papermill": {
     "duration": 0.017213,
     "end_time": "2025-02-16T20:08:20.170300",
     "exception": false,
     "start_time": "2025-02-16T20:08:20.153087",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SRGAN Model Components\n",
    "\n",
    "# Residual Block for SRGAN\n",
    "def residual_block(input_tensor, filters=64):\n",
    "    x = Conv2D(filters, (3,3), padding='same')(input_tensor)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = PReLU(shared_axes=[1,2])(x)\n",
    "    x = Conv2D(filters, (3,3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    return add([input_tensor, x])\n",
    "\n",
    "# Upscale Block with sub-pixel convolution (using UpSampling2D)\n",
    "def upscale_block(input_tensor, filters=256):\n",
    "    x = UpSampling2D(size=2)(input_tensor)\n",
    "    x = Conv2D(filters, (3,3), padding='same')(x)\n",
    "    return PReLU(shared_axes=[1,2])(x)\n",
    "\n",
    "# SRGAN Generator\n",
    "def create_gen(gen_ip, num_res_block=16):\n",
    "    x = Conv2D(64, (3,3), padding='same')(gen_ip)\n",
    "    x = PReLU(shared_axes=[1,2])(x)\n",
    "    temp = x\n",
    "    for _ in range(num_res_block):\n",
    "        x = residual_block(x)\n",
    "    x = Conv2D(64, (3,3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = add([x, temp])\n",
    "    x = upscale_block(x, 256)\n",
    "    x = upscale_block(x, 256)\n",
    "    x = Conv2D(3, (3,3), padding='same', activation='sigmoid', dtype='float32')(x)\n",
    "    return Model(gen_ip, x)\n",
    "\n",
    "# SRGAN Discriminator\n",
    "def create_disc(disc_ip):\n",
    "    df = 64\n",
    "    x = Conv2D(df, (3,3), padding='same')(disc_ip)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    x = Conv2D(df, (3,3), strides=2, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    x = Conv2D(df*2, (3,3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    x = Conv2D(df*2, (3,3), strides=2, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    x = Conv2D(df*4, (3,3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    x = Conv2D(df*4, (3,3), strides=2, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    x = Conv2D(df*8, (3,3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    x = Conv2D(df*8, (3,3), strides=2, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(df*16)(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "    return Model(disc_ip, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcec0e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-16T20:08:20.179487Z",
     "iopub.status.busy": "2025-02-16T20:08:20.179237Z",
     "iopub.status.idle": "2025-02-16T20:08:20.183077Z",
     "shell.execute_reply": "2025-02-16T20:08:20.182524Z"
    },
    "papermill": {
     "duration": 0.009726,
     "end_time": "2025-02-16T20:08:20.184198",
     "exception": false,
     "start_time": "2025-02-16T20:08:20.174472",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# VGG19 Feature Extractor: \n",
    "def build_vgg(hr_shape):\n",
    "    inp = Input(shape=hr_shape, dtype='float32')\n",
    "    preprocessed = Lambda(lambda x: preprocess_input(x * 255.0), output_shape=lambda s: s)(inp)\n",
    "    base_vgg = VGG19(weights=\"imagenet\", include_top=False, input_tensor=preprocessed)\n",
    "    features = base_vgg.get_layer(\"block3_conv3\").output\n",
    "    reduced_features = Conv2D(64, (1,1), padding='same', activation='linear')(features)\n",
    "    return Model(inputs=inp, outputs=reduced_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a636d3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-16T20:08:20.192870Z",
     "iopub.status.busy": "2025-02-16T20:08:20.192667Z",
     "iopub.status.idle": "2025-02-16T20:08:20.196106Z",
     "shell.execute_reply": "2025-02-16T20:08:20.195506Z"
    },
    "papermill": {
     "duration": 0.009108,
     "end_time": "2025-02-16T20:08:20.197268",
     "exception": false,
     "start_time": "2025-02-16T20:08:20.188160",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Combined model for perceptual loss\n",
    "def create_comb(gen_model, disc_model, vgg, lr_ip, hr_ip):\n",
    "    gen_img = gen_model(lr_ip)\n",
    "    gen_features = vgg(gen_img)\n",
    "    disc_model.trainable = False\n",
    "    validity = disc_model(gen_img)\n",
    "    return Model(inputs=[lr_ip, hr_ip], outputs=[validity, gen_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f0bc59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-16T20:08:20.205775Z",
     "iopub.status.busy": "2025-02-16T20:08:20.205576Z",
     "iopub.status.idle": "2025-02-16T20:08:41.627877Z",
     "shell.execute_reply": "2025-02-16T20:08:41.626939Z"
    },
    "papermill": {
     "duration": 21.427974,
     "end_time": "2025-02-16T20:08:41.629242",
     "exception": false,
     "start_time": "2025-02-16T20:08:20.201268",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data Loading\n",
    "n = 5000  # Number of images to use\n",
    "lr_path = \"/kaggle/input/sr-data/DATASET/AUG/LR_Aug\"\n",
    "hr_path = \"/kaggle/input/sr-data/DATASET/AUG/HR_Aug\"\n",
    "\n",
    "lr_list = os.listdir(lr_path)[:n]\n",
    "hr_list = os.listdir(hr_path)[:n]\n",
    "\n",
    "lr_images = []\n",
    "hr_images = []\n",
    "\n",
    "# Load images and keep them in BGR (for VGG)\n",
    "for img in lr_list:\n",
    "    img_path = os.path.join(lr_path, img)\n",
    "    img_lr = cv2.imread(img_path)  # BGR format\n",
    "    lr_images.append(img_lr)\n",
    "\n",
    "for img in hr_list:\n",
    "    img_path = os.path.join(hr_path, img)\n",
    "    img_hr = cv2.imread(img_path)  # BGR format\n",
    "    hr_images.append(img_hr)\n",
    "\n",
    "lr_images = np.array(lr_images, dtype=np.float32) / 255.0\n",
    "hr_images = np.array(hr_images, dtype=np.float32) / 255.0\n",
    "\n",
    "print(f\"LR shape: {lr_images[0].shape}, HR shape: {hr_images[0].shape}\")\n",
    "print(f\"LR range: [{lr_images.min()}, {lr_images.max()}]\")\n",
    "print(f\"HR range: [{hr_images.min()}, {hr_images.max()}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59606ec6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-16T20:08:41.639044Z",
     "iopub.status.busy": "2025-02-16T20:08:41.638753Z",
     "iopub.status.idle": "2025-02-16T20:08:41.904750Z",
     "shell.execute_reply": "2025-02-16T20:08:41.903909Z"
    },
    "papermill": {
     "duration": 0.273624,
     "end_time": "2025-02-16T20:08:41.907737",
     "exception": false,
     "start_time": "2025-02-16T20:08:41.634113",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualizing Random Images\n",
    "random_idx = random.randint(0, len(lr_images)-1)\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.imshow(bgr_to_rgb(lr_images[random_idx]))\n",
    "plt.title(\" LR Sample \")\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.imshow(bgr_to_rgb(hr_images[random_idx]))\n",
    "plt.title(\" HR Sample \")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5a33be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-16T20:08:41.924238Z",
     "iopub.status.busy": "2025-02-16T20:08:41.923992Z",
     "iopub.status.idle": "2025-02-16T20:08:42.281592Z",
     "shell.execute_reply": "2025-02-16T20:08:42.280361Z"
    },
    "papermill": {
     "duration": 0.36774,
     "end_time": "2025-02-16T20:08:42.283256",
     "exception": false,
     "start_time": "2025-02-16T20:08:41.915516",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "lr_train, lr_test, hr_train, hr_test = train_test_split(lr_images, hr_images, test_size=0.33, random_state=42)\n",
    "hr_shape = (256,256,3)\n",
    "lr_shape = (64,64,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7b115c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-16T20:08:42.299335Z",
     "iopub.status.busy": "2025-02-16T20:08:42.299063Z",
     "iopub.status.idle": "2025-02-16T20:08:44.221549Z",
     "shell.execute_reply": "2025-02-16T20:08:44.220611Z"
    },
    "papermill": {
     "duration": 1.933869,
     "end_time": "2025-02-16T20:08:44.224956",
     "exception": false,
     "start_time": "2025-02-16T20:08:42.291087",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Model Initialization\n",
    "generator = create_gen(Input(lr_shape))\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d10b52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-16T20:08:44.246003Z",
     "iopub.status.busy": "2025-02-16T20:08:44.245741Z",
     "iopub.status.idle": "2025-02-16T20:08:44.413703Z",
     "shell.execute_reply": "2025-02-16T20:08:44.412969Z"
    },
    "papermill": {
     "duration": 0.179552,
     "end_time": "2025-02-16T20:08:44.415073",
     "exception": false,
     "start_time": "2025-02-16T20:08:44.235521",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "discriminator = create_disc(Input(hr_shape))\n",
    "discriminator.compile(loss=\"binary_crossentropy\", optimizer=disc_optimizer, metrics=['accuracy'])\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d60c7f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-16T20:08:44.437913Z",
     "iopub.status.busy": "2025-02-16T20:08:44.437664Z",
     "iopub.status.idle": "2025-02-16T20:08:45.237698Z",
     "shell.execute_reply": "2025-02-16T20:08:45.236828Z"
    },
    "papermill": {
     "duration": 0.812943,
     "end_time": "2025-02-16T20:08:45.239646",
     "exception": false,
     "start_time": "2025-02-16T20:08:44.426703",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "vgg = build_vgg(hr_shape)\n",
    "print(vgg.summary())\n",
    "vgg.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266645fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-16T20:08:45.264760Z",
     "iopub.status.busy": "2025-02-16T20:08:45.264537Z",
     "iopub.status.idle": "2025-02-16T20:08:47.267125Z",
     "shell.execute_reply": "2025-02-16T20:08:47.266315Z"
    },
    "papermill": {
     "duration": 2.016343,
     "end_time": "2025-02-16T20:08:47.268656",
     "exception": false,
     "start_time": "2025-02-16T20:08:45.252313",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training Parameters\n",
    "batch_size = 6\n",
    "epochs = 85 # Adjust as needed\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((lr_train, hr_train)).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87ef885",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-16T20:08:47.294908Z",
     "iopub.status.busy": "2025-02-16T20:08:47.294665Z",
     "iopub.status.idle": "2025-02-16T20:08:47.297829Z",
     "shell.execute_reply": "2025-02-16T20:08:47.297209Z"
    },
    "papermill": {
     "duration": 0.017513,
     "end_time": "2025-02-16T20:08:47.298957",
     "exception": false,
     "start_time": "2025-02-16T20:08:47.281444",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loss tracking lists\n",
    "gen_losses = []\n",
    "disc_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d5763b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-16T20:08:47.323451Z",
     "iopub.status.busy": "2025-02-16T20:08:47.323230Z",
     "iopub.status.idle": "2025-02-17T07:55:45.027451Z",
     "shell.execute_reply": "2025-02-17T07:55:45.026605Z"
    },
    "papermill": {
     "duration": 42417.718197,
     "end_time": "2025-02-17T07:55:45.028993",
     "exception": false,
     "start_time": "2025-02-16T20:08:47.310796",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training Loop \n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
    "    epoch_gen_loss = 0.0\n",
    "    epoch_disc_loss = 0.0\n",
    "    num_batches = 0\n",
    "    \n",
    "    for lr_batch, hr_batch in tqdm(train_dataset, desc=\"Training Epoch\"):\n",
    "        # Train Discriminator\n",
    "        with tf.GradientTape() as disc_tape:\n",
    "            fake_hr = generator(lr_batch, training=True)\n",
    "            real_output = discriminator(hr_batch, training=True)\n",
    "            fake_output = discriminator(fake_hr, training=True)\n",
    "            \n",
    "            real_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                labels=tf.ones_like(real_output),\n",
    "                logits=real_output - tf.reduce_mean(fake_output)\n",
    "            ))\n",
    "            fake_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                labels=tf.zeros_like(fake_output),\n",
    "                logits=fake_output - tf.reduce_mean(real_output)\n",
    "            ))\n",
    "            disc_loss = 0.5 * (real_loss + fake_loss)\n",
    "        \n",
    "        disc_grads = disc_tape.gradient(disc_loss, discriminator.trainable_weights)\n",
    "        disc_optimizer.apply_gradients(zip(disc_grads, discriminator.trainable_weights))\n",
    "        \n",
    "        # Train Generator\n",
    "        with tf.GradientTape() as gen_tape:\n",
    "            fake_hr = generator(lr_batch, training=True)\n",
    "            fake_output = discriminator(fake_hr, training=False)\n",
    "            real_output = discriminator(hr_batch, training=False)\n",
    "            \n",
    "            gen_adv_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                labels=tf.ones_like(fake_output),\n",
    "                logits=fake_output - tf.reduce_mean(real_output)\n",
    "            ))\n",
    "            \n",
    "            gen_features = vgg(fake_hr)\n",
    "            real_features = vgg(hr_batch)\n",
    "            gen_content_loss = tf.reduce_mean(tf.square(gen_features - real_features))\n",
    "            \n",
    "            # Increase adversarial weight to 1e-2 for generator priority\n",
    "            gen_total_loss = gen_content_loss + 1e-2 * gen_adv_loss\n",
    "            \n",
    "        gen_grads = gen_tape.gradient(gen_total_loss, generator.trainable_weights)\n",
    "        gen_optimizer.apply_gradients(zip(gen_grads, generator.trainable_weights))\n",
    "        \n",
    "        epoch_gen_loss += gen_total_loss.numpy()\n",
    "        epoch_disc_loss += disc_loss.numpy()\n",
    "        num_batches += 1\n",
    "    \n",
    "    avg_gen_loss = epoch_gen_loss / num_batches\n",
    "    avg_disc_loss = epoch_disc_loss / num_batches\n",
    "    print(f\"Epoch {epoch+1}: Generator Loss = {avg_gen_loss:.4f}, Discriminator Loss = {avg_disc_loss:.4f}\")\n",
    "    \n",
    "    gen_losses.append(avg_gen_loss)\n",
    "    disc_losses.append(avg_disc_loss)\n",
    "\n",
    "# Save final generator\n",
    "generator.save(\"srgan_generator_final.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d8d6eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T07:55:46.552953Z",
     "iopub.status.busy": "2025-02-17T07:55:46.552626Z",
     "iopub.status.idle": "2025-02-17T07:55:46.763439Z",
     "shell.execute_reply": "2025-02-17T07:55:46.762424Z"
    },
    "papermill": {
     "duration": 1.046293,
     "end_time": "2025-02-17T07:55:46.765085",
     "exception": false,
     "start_time": "2025-02-17T07:55:45.718792",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "generator.save(\"srgan_generator_final.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d90e7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T07:55:48.143747Z",
     "iopub.status.busy": "2025-02-17T07:55:48.143421Z",
     "iopub.status.idle": "2025-02-17T07:56:27.987393Z",
     "shell.execute_reply": "2025-02-17T07:56:27.986519Z"
    },
    "papermill": {
     "duration": 40.534875,
     "end_time": "2025-02-17T07:56:27.988957",
     "exception": false,
     "start_time": "2025-02-17T07:55:47.454082",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluation Metrics\n",
    "def evaluate_gan(generator, lr_test, hr_test, batch_size=8):\n",
    "    psnr_values = []\n",
    "    ssim_values = []\n",
    "    mse_values = []\n",
    "    lr_samples = []\n",
    "    hr_samples = []\n",
    "    sr_samples = []\n",
    "    \n",
    "    for i in tqdm(range(0, len(lr_test), batch_size), desc=\"Generating SR images\"):\n",
    "        lr_batch = lr_test[i:i+batch_size]\n",
    "        hr_batch = hr_test[i:i+batch_size]\n",
    "        \n",
    "        sr_batch = generator.predict(lr_batch, verbose=0)\n",
    "        sr_batch = np.clip(sr_batch, 0.0, 1.0)\n",
    "        \n",
    "        for j in range(len(hr_batch)):\n",
    "            psnr_val = psnr(hr_batch[j], sr_batch[j], data_range=1.0)\n",
    "            ssim_val = ssim(hr_batch[j], sr_batch[j], data_range=1.0, channel_axis=-1)\n",
    "            mse_val = np.mean((hr_batch[j] - sr_batch[j]) ** 2)\n",
    "            \n",
    "            psnr_values.append(psnr_val)\n",
    "            ssim_values.append(ssim_val)\n",
    "            mse_values.append(mse_val)\n",
    "        \n",
    "        lr_samples.extend(lr_batch)\n",
    "        hr_samples.extend(hr_batch)\n",
    "        sr_samples.extend(sr_batch)\n",
    "    \n",
    "    return {\n",
    "        'psnr': psnr_values,\n",
    "        'ssim': ssim_values,\n",
    "        'mse': mse_values,\n",
    "        'lr_samples': np.array(lr_samples),\n",
    "        'hr_samples': np.array(hr_samples),\n",
    "        'sr_samples': np.array(sr_samples)\n",
    "    }\n",
    "\n",
    "gan_metrics = evaluate_gan(generator, lr_test, hr_test)\n",
    "print(\"Mean PSNR:\", np.mean(gan_metrics['psnr']))\n",
    "print(\"Mean SSIM:\", np.mean(gan_metrics['ssim']))\n",
    "print(\"Mean MSE: \", np.mean(gan_metrics['mse']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0cda79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T07:56:29.571822Z",
     "iopub.status.busy": "2025-02-17T07:56:29.571508Z",
     "iopub.status.idle": "2025-02-17T07:56:29.935847Z",
     "shell.execute_reply": "2025-02-17T07:56:29.934997Z"
    },
    "papermill": {
     "duration": 1.062781,
     "end_time": "2025-02-17T07:56:29.937179",
     "exception": false,
     "start_time": "2025-02-17T07:56:28.874398",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loss Visualization \n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(1, epochs+1), gen_losses, color='blue', marker='o', label='Generator Loss')\n",
    "plt.title('Generator Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(1, epochs+1), disc_losses, color='orange', marker='o', label='Discriminator Loss')\n",
    "plt.title('Discriminator Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149479d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T07:56:31.343965Z",
     "iopub.status.busy": "2025-02-17T07:56:31.343651Z",
     "iopub.status.idle": "2025-02-17T07:56:32.699023Z",
     "shell.execute_reply": "2025-02-17T07:56:32.698179Z"
    },
    "papermill": {
     "duration": 2.066755,
     "end_time": "2025-02-17T07:56:32.705691",
     "exception": false,
     "start_time": "2025-02-17T07:56:30.638936",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sample Comparisons\n",
    "def plot_gan_samples(gan_metrics, num_samples=3):\n",
    "    indices = np.random.choice(len(gan_metrics['lr_samples']), num_samples)\n",
    "    for idx in indices:\n",
    "        plt.figure(figsize=(12,6))\n",
    "        # LR Input (BGR -> RGB for display)\n",
    "        plt.subplot(241)\n",
    "        lr_bgr = gan_metrics['lr_samples'][idx]\n",
    "        plt.imshow(bgr_to_rgb(lr_bgr))\n",
    "        plt.title('LR Input')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # HR Target (BGR -> RGB for display)\n",
    "        plt.subplot(242)\n",
    "        hr_bgr = gan_metrics['hr_samples'][idx]\n",
    "        plt.imshow(bgr_to_rgb(hr_bgr))\n",
    "        plt.title('HR Target')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # SR Output (BGR -> RGB for display)\n",
    "        plt.subplot(243)\n",
    "        sr_bgr = gan_metrics['sr_samples'][idx]\n",
    "        metrics_text = f\"PSNR: {gan_metrics['psnr'][idx]:.2f}\\nSSIM: {gan_metrics['ssim'][idx]:.4f}\\nMSE: {gan_metrics['mse'][idx]:.5f}\"\n",
    "        plt.imshow(bgr_to_rgb(sr_bgr))\n",
    "        plt.title('SRGAN Output\\n' + metrics_text)\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Error Map\n",
    "        plt.subplot(244)\n",
    "        error = np.abs(hr_bgr - sr_bgr)\n",
    "        plt.imshow(np.mean(error, axis=-1), cmap='inferno', vmin=0, vmax=0.07)\n",
    "        plt.title('Pixel Error Heatmap')\n",
    "        plt.colorbar()\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "plot_gan_samples(gan_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9929e847",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T07:56:34.304428Z",
     "iopub.status.busy": "2025-02-17T07:56:34.303937Z",
     "iopub.status.idle": "2025-02-17T07:56:35.053123Z",
     "shell.execute_reply": "2025-02-17T07:56:35.052165Z"
    },
    "papermill": {
     "duration": 1.479474,
     "end_time": "2025-02-17T07:56:35.054820",
     "exception": false,
     "start_time": "2025-02-17T07:56:33.575346",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Metric Distributions\n",
    "def plot_gan_metrics(gan_metrics):\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(18,5))\n",
    "    metrics = ['psnr', 'ssim', 'mse']\n",
    "    titles = ['PSNR Distribution', 'SSIM Distribution', 'MSE Distribution']\n",
    "    colors = ['purple', 'green', 'red']\n",
    "    for ax, metric, title, color in zip(axs, metrics, titles, colors):\n",
    "        ax.hist(gan_metrics[metric], bins=30, alpha=0.7, color=color)\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel(metric.upper())\n",
    "        ax.set_ylabel('Frequency')\n",
    "        mean_val = np.mean(gan_metrics[metric])\n",
    "        ax.axvline(mean_val, color='black', linestyle='dashed', linewidth=2, label=f'Mean: {mean_val:.2f}')\n",
    "        ax.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_gan_metrics(gan_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5e8272",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T07:56:36.544167Z",
     "iopub.status.busy": "2025-02-17T07:56:36.543848Z",
     "iopub.status.idle": "2025-02-17T07:56:39.160428Z",
     "shell.execute_reply": "2025-02-17T07:56:39.159561Z"
    },
    "papermill": {
     "duration": 3.339133,
     "end_time": "2025-02-17T07:56:39.162089",
     "exception": false,
     "start_time": "2025-02-17T07:56:35.822956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Error Analysis\n",
    "def plot_gan_error_analysis(gan_metrics):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12,5))\n",
    "    errors = np.concatenate([np.abs(hr - sr) for hr, sr in zip(gan_metrics['hr_samples'], gan_metrics['sr_samples'])])\n",
    "    axs[0].hist(errors.flatten(), bins=50, color='darkorange', density=True)\n",
    "    axs[0].set_title('Pixel Error Distribution')\n",
    "    axs[0].set_xlabel('Absolute Error')\n",
    "    axs[0].set_ylabel('Density')\n",
    "    \n",
    "    axs[1].scatter(gan_metrics['psnr'], gan_metrics['ssim'], alpha=0.5)\n",
    "    axs[1].set_title('PSNR vs SSIM Correlation')\n",
    "    axs[1].set_xlabel('PSNR')\n",
    "    axs[1].set_ylabel('SSIM')\n",
    "    \n",
    "    psnr_data = np.array(gan_metrics['psnr'])\n",
    "    ssim_data = np.array(gan_metrics['ssim'])\n",
    "    X = psnr_data.reshape(-1, 1)\n",
    "    y = ssim_data\n",
    "    m, _, _, _ = np.linalg.lstsq(X, y, rcond=None)\n",
    "    \n",
    "    x_line = np.linspace(0, psnr_data.max(), 100)\n",
    "    y_line = m[0] * x_line\n",
    "    axs[1].plot(x_line, y_line, color='red', linestyle='--', label=f'Trend: y = {m[0]:.5f}x')\n",
    "    axs[1].legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_gan_error_analysis(gan_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a372f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T07:56:40.758544Z",
     "iopub.status.busy": "2025-02-17T07:56:40.758017Z",
     "iopub.status.idle": "2025-02-17T07:56:40.761785Z",
     "shell.execute_reply": "2025-02-17T07:56:40.761110Z"
    },
    "papermill": {
     "duration": 0.86481,
     "end_time": "2025-02-17T07:56:40.762946",
     "exception": false,
     "start_time": "2025-02-17T07:56:39.898136",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#----Test with New Dataset ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fa56c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T07:56:42.314175Z",
     "iopub.status.busy": "2025-02-17T07:56:42.313826Z",
     "iopub.status.idle": "2025-02-17T07:56:45.438102Z",
     "shell.execute_reply": "2025-02-17T07:56:45.437161Z"
    },
    "papermill": {
     "duration": 3.877519,
     "end_time": "2025-02-17T07:56:45.439638",
     "exception": false,
     "start_time": "2025-02-17T07:56:41.562119",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#  Load New Dataset (SRGAN)\n",
    "\n",
    "new_lr_dir = \"/kaggle/input/test-sr/testing dataset/LR\"\n",
    "new_hr_dir = \"/kaggle/input/test-sr/testing dataset/HR\"\n",
    "\n",
    "def load_images_rgb(folder, resize_shape):\n",
    "    filenames = sorted(os.listdir(folder))\n",
    "    images = []\n",
    "    for file in filenames:\n",
    "        path = os.path.join(folder, file)\n",
    "        img = cv2.imread(path)\n",
    "        if img is not None:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = cv2.resize(img, resize_shape)\n",
    "            images.append(img)\n",
    "    return np.array(images, dtype=np.float32)/255.0\n",
    "\n",
    "# For SRGAN, LR=64×64, HR=256×256\n",
    "new_lr_images = load_images_rgb(new_lr_dir, (64,64))\n",
    "new_hr_images = load_images_rgb(new_hr_dir, (256,256))\n",
    "\n",
    "\n",
    "# Evaluate on New Dataset\n",
    "\n",
    "new_gan_metrics = evaluate_gan(generator, new_lr_images, new_hr_images)\n",
    "\n",
    "\n",
    "# Print Side-by-Side Table\n",
    "orig_psnr = np.mean(gan_metrics['psnr'])\n",
    "orig_ssim = np.mean(gan_metrics['ssim'])\n",
    "orig_mse  = np.mean(gan_metrics['mse'])\n",
    "\n",
    "new_psnr = np.mean(new_gan_metrics['psnr'])\n",
    "new_ssim = np.mean(new_gan_metrics['ssim'])\n",
    "new_mse  = np.mean(new_gan_metrics['mse'])\n",
    "\n",
    "print(\"\\n==================== SRGAN PERFORMANCE COMPARISON ====================\")\n",
    "print(f\"{'Metric':<8} | {'Original':>10} | {'New':>10} | {'Diff':>10}\")\n",
    "print(\"-\"*56)\n",
    "\n",
    "for name, o_val, n_val in zip([\"PSNR\",\"SSIM\",\"MSE\"], [orig_psnr,orig_ssim,orig_mse], [new_psnr,new_ssim,new_mse]):\n",
    "    diff = n_val - o_val\n",
    "    print(f\"{name:<8} | {o_val:10.4f} | {n_val:10.4f} | {diff:10.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7963e856",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T07:56:47.034047Z",
     "iopub.status.busy": "2025-02-17T07:56:47.033728Z",
     "iopub.status.idle": "2025-02-17T07:56:47.471839Z",
     "shell.execute_reply": "2025-02-17T07:56:47.470926Z"
    },
    "papermill": {
     "duration": 1.307138,
     "end_time": "2025-02-17T07:56:47.473246",
     "exception": false,
     "start_time": "2025-02-17T07:56:46.166108",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot Bar Charts\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "metrics = [\"PSNR\",\"SSIM\",\"MSE\"]\n",
    "orig_data = [orig_psnr, orig_ssim, orig_mse]\n",
    "new_data  = [new_psnr, new_ssim, new_mse]\n",
    "colors = [\"blue\",\"orange\"]\n",
    "\n",
    "for i, (metric, orig_val, new_val) in enumerate(zip(metrics, orig_data, new_data)):\n",
    "    plt.subplot(1,3,i+1)\n",
    "    plt.bar([\"Original\",\"New\"], [orig_val,new_val], color=colors)\n",
    "    plt.title(f\"{metric} Comparison\")\n",
    "    plt.ylabel(metric)\n",
    "\n",
    "plt.suptitle(\"SRGAN Metric Comparison\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6581528,
     "sourceId": 10629620,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6585716,
     "sourceId": 10636715,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6631100,
     "sourceId": 10700442,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6677678,
     "sourceId": 10764989,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6590540,
     "sourceId": 10643951,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30887,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 42528.037904,
   "end_time": "2025-02-17T07:56:50.833275",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-16T20:08:02.795371",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
